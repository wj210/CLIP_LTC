# Debiasing CLIP: Interpreting and Correcting Bias in Attention Heads

![Alt text](images/overall.png)

This work is adapted from **Interpreting CLIP's Image Representation via Text-Based Decomposition** https://github.com/yossigandelsman/clip_text_span

The models supported are `ViT-B-16, ViT-L-14 and ViT-H-14`, datasets: `binary_waterbirds, genderbias, fairface and counteranimal`. Use this in the arguments below.

# Setup
Install via the requirements.txt file by running `pip install -r requirements.txt`

# Dataset installation
Set your image_dir in the `root` variable in `dataset/data_utils.py`

To download the **Waterbirds** datasets, run:
```python
wget https://nlp.stanford.edu/data/dro/waterbird_complete95_forest2water2.tar.gz
tar -xf  waterbird_complete95_forest2water2.tar.gz
```

For **GenderBias**, follow https://github.com/GenderBiasVL/GenderBias-VL and download `xl_generate_base.tar.gz` from https://huggingface.co/datasets/xiaoyisong/GenderBias-VL/tree/main, store it and untar under `root` and change the name to `genderbias_xl`

For **CounterAnimal**, download from https://counteranimal.github.io/

For **Fairface**, download from https://github.com/joojs/fairface?tab=readme-ov-file, we use padding=1.25

# Retreiving Attention States
Retrieve and store attention states from each head and layer from the CLIP model.

Run the following instructions by changing `dataset, model` accordingly. For **fairface**, you do not need to run the second line, as it is automatically set to use the test-set, we do not need the train set:
```python
python compute_prs.py --dataset binary_waterbirds --model ViT-B-16 --batch_size 16
python compute_prs.py --dataset binary_waterbirds --model ViT-B-16 --batch_size 16 --test
```

# Get Results
For **Background Bias** - Waterbirds and CounterAnimal

Run:
```python
python main_bg.py --dataset binary_waterbirds --model ViT-B-16
```

For **Gender bias** - GenderBias and Fairface

Run:
```python
python main_gender.py --dataset genderbias --model ViT-B-16
```

# Visualization 

![Alt text](images/viz.png)

For Text, run:
```python
python viz_text.py --dataset genderbias --model ViT-B-16
```

For Image, run:
```python
python viz_img.py --dataset genderbias --model ViT-B-16
```
